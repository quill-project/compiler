
mod quill::tests::lexer

use std::test::*
use quill::*
use quill::token::(Token, TokenType)

pub fun is_alphabetic() {
    assert_eq(lexer::is_alphabetic("A"), true)
    assert_eq(lexer::is_alphabetic("a"), true)
    assert_eq(lexer::is_alphabetic("c"), true)
    assert_eq(lexer::is_alphabetic("F"), true)
    assert_eq(lexer::is_alphabetic("Q"), true)
    assert_eq(lexer::is_alphabetic("z"), true)
    assert_eq(lexer::is_alphabetic("Z"), true)
    assert_eq(lexer::is_alphabetic("@"), false)
    assert_eq(lexer::is_alphabetic("."), false)
    assert_eq(lexer::is_alphabetic("!"), false)
}

pub fun is_numeric() {
    assert_eq(lexer::is_numeric("1"), true)
    assert_eq(lexer::is_numeric("2"), true)
    assert_eq(lexer::is_numeric("3"), true)
    assert_eq(lexer::is_numeric("4"), true)
    assert_eq(lexer::is_numeric("5"), true)
    assert_eq(lexer::is_numeric("6"), true)
    assert_eq(lexer::is_numeric("7"), true)
    assert_eq(lexer::is_numeric("8"), true)
    assert_eq(lexer::is_numeric("9"), true)
    assert_eq(lexer::is_numeric("0"), true)
    assert_eq(lexer::is_numeric("_"), false)
    assert_eq(lexer::is_numeric("."), false)
    assert_eq(lexer::is_numeric("!"), false)
}

pub fun is_alphanumeric() {
    assert_eq(lexer::is_alphanumeric("1"), true)
    assert_eq(lexer::is_alphanumeric("2"), true)
    assert_eq(lexer::is_alphanumeric("3"), true)
    assert_eq(lexer::is_alphanumeric("9"), true)
    assert_eq(lexer::is_alphanumeric("0"), true)
    assert_eq(lexer::is_alphanumeric("_"), true)
    assert_eq(lexer::is_alphanumeric("A"), true)
    assert_eq(lexer::is_alphanumeric("a"), true)
    assert_eq(lexer::is_alphanumeric("z"), true)
    assert_eq(lexer::is_alphanumeric("Z"), true)
    assert_eq(lexer::is_alphanumeric("."), false)
    assert_eq(lexer::is_alphanumeric("!"), false)
    assert_eq(lexer::is_alphanumeric("@"), false)
}

pub fun is_whitespace() {
    assert_eq(lexer::is_whitespace(" "), true)
    assert_eq(lexer::is_whitespace("\n"), true)
    assert_eq(lexer::is_whitespace("\r"), true)
    assert_eq(lexer::is_whitespace("\x09"), true) // horizontal tab
    assert_eq(lexer::is_whitespace("\x0B"), true) // vertical tab
    assert_eq(lexer::is_whitespace("z"), false)
    assert_eq(lexer::is_whitespace("Z"), false)
    assert_eq(lexer::is_whitespace("."), false)
    assert_eq(lexer::is_whitespace("!"), false)
    assert_eq(lexer::is_whitespace("@"), false)
}

pub fun parse_hex_digit() {
    assert_eq(lexer::parse_hex_digit("2"), Option::Some(2))
    assert_eq(lexer::parse_hex_digit("F"), Option::Some(15))
    assert_eq(lexer::parse_hex_digit("8"), Option::Some(8))
    assert_eq(lexer::parse_hex_digit("c"), Option::Some(12))
    assert_eq(lexer::parse_hex_digit("e"), Option::Some(14))
    assert_eq(lexer::parse_hex_digit("g"), Option::None)
    assert_eq(lexer::parse_hex_digit("@"), Option::None)
    assert_eq(lexer::parse_hex_digit("z"), Option::None)
}

pub fun parse_hex_number() {
    assert_eq(lexer::parse_hex_number("12"), Option::Some(18))
    assert_eq(lexer::parse_hex_number("2F"), Option::Some(47))
    assert_eq(lexer::parse_hex_number("CC"), Option::Some(204))
    assert_eq(lexer::parse_hex_number("DEADBEEF"), Option::Some(3735928559))
    assert_eq(lexer::parse_hex_number("FFFF"), Option::Some(65535))
    assert_eq(lexer::parse_hex_number("FFGF"), Option::None)
    assert_eq(lexer::parse_hex_number("12VF"), Option::None)
    assert_eq(lexer::parse_hex_number("@as2"), Option::None)
}


struct TToken(type: TokenType, content: String, start: Int, end: Int)

fun TToken::as_string(self: TToken) -> String 
    = "Token(_, _, _.._)" |> fmt(
        self.type |> as_string(), 
        self.content, 
        self.start |> as_string(), self.end |> as_string()
    )

fun assert_tokens(content: String, ...expected: List[TToken]) {
    val messages: mut List[Message] = List::empty()
    val output: List[TToken] 
        = lexer::tokenize_all("test.quill", content, messages)
        |> take_until(|t| t.type == TokenType::EndOfFile)
        |> map[Token, TToken](|t| {
            assert_eq(t.source.path, "test.quill")
            return TToken(t.type, t.content, t.source.start, t.source.end)
        })
        |> List::collect()
    if messages |> values() |> any(Message::is_error) {
        val files = Map::of(Pair("test.quill", content))
        val msgs = messages 
            |> values() |> map[Message, String](|m| m |> display(files)) 
            |> join("\n\n")
        return "Parsing assertion failed:\n" |> concat(content)
            |> concat("\n\nParser reported message(s):\n") |> concat(msgs)
            |> panic()
    }
    if output == expected { return unit }
    return "Lexing assertion failed:\n"
        |> concat(content)
        |> concat("\n\nTest expected:\n")
        |> concat(expected |> values() |> map(TToken::as_string) |> join("\n"))
        |> concat("\n\nLexer returned:\n")
        |> concat(output |> values() |> map(TToken::as_string) |> join("\n"))
        |> panic()
}

pub fun int_literals() = assert_tokens(
    "5 10 251234 5942 -5",

    TToken(TokenType::IntLiteral, "5",       0,  1),
    TToken(TokenType::Whitespace, " ",       1,  2),
    TToken(TokenType::IntLiteral, "10",      2,  4),
    TToken(TokenType::Whitespace, " ",       4,  5),
    TToken(TokenType::IntLiteral, "251234",  5, 11),
    TToken(TokenType::Whitespace, " ",      11, 12),
    TToken(TokenType::IntLiteral, "5942",   12, 16),
    TToken(TokenType::Whitespace, " ",      16, 17),
    TToken(TokenType::Minus,      "-",      17, 18),
    TToken(TokenType::IntLiteral, "5",      18, 19)
)

pub fun float_literals() = assert_tokens(
    "3.5 .125 0.75 3. -0.5",

    TToken(TokenType::FloatLiteral, "3.5",   0,  3),
    TToken(TokenType::Whitespace,   " ",     3,  4),
    TToken(TokenType::Dot,          ".",     4,  5),
    TToken(TokenType::IntLiteral,   "125",   5,  8),
    TToken(TokenType::Whitespace,   " ",     8,  9),
    TToken(TokenType::FloatLiteral, "0.75",  9, 13),
    TToken(TokenType::Whitespace,   " ",    13, 14),
    TToken(TokenType::FloatLiteral, "3.",   14, 16),
    TToken(TokenType::Whitespace,   " ",    16, 17),
    TToken(TokenType::Minus,        "-",    17, 18),
    TToken(TokenType::FloatLiteral, "0.5",  18, 21)
)

pub fun keyword_literals() = assert_tokens(
    "true false unit",


    TToken(TokenType::BoolLiteral, "true",   0,  4),
    TToken(TokenType::Whitespace,  " ",      4,  5),
    TToken(TokenType::BoolLiteral, "false",  5, 10),
    TToken(TokenType::Whitespace,  " ",     10, 11),
    TToken(TokenType::UnitLiteral, "unit",  11, 15)
)

pub fun string_literals() = assert_tokens(
    "\"hello\"  \"hello\\nworld\" \"\\
heya\" \"\\x4C\\x4F\\x4C\" \"\\u2122\"",

    TToken(TokenType::StringLiteral, "hello",         0,  7),
    TToken(TokenType::Whitespace,    "  ",            7,  9),
    TToken(TokenType::StringLiteral, "hello\nworld",  9, 23),
    TToken(TokenType::Whitespace,    " ",            23, 24),
    TToken(TokenType::StringLiteral, "heya",         24, 32),
    TToken(TokenType::Whitespace,    " ",            32, 33),
    TToken(TokenType::StringLiteral, "LOL",          33, 47),
    TToken(TokenType::Whitespace,    " ",            47, 48),
    TToken(TokenType::StringLiteral, "â„¢",            48, 56),
)

pub fun symbols() = assert_tokens(
    "... <= >= == != -> && || :: |> ()[]{} < > = + - * / % : , ! . |",

    TToken(TokenType::TripleDots,       "...",  0,  3),
    TToken(TokenType::Whitespace,       " ",    3,  4),
    TToken(TokenType::LessThanEqual,    "<=",   4,  6),
    TToken(TokenType::Whitespace,       " ",    6,  7),
    TToken(TokenType::GreaterThanEqual, ">=",   7,  9),
    TToken(TokenType::Whitespace,       " ",    9, 10),
    TToken(TokenType::DoubleEqual,      "==",  10, 12),
    TToken(TokenType::Whitespace,       " ",   12, 13),
    TToken(TokenType::NotEqual,         "!=",  13, 15),
    TToken(TokenType::Whitespace,       " ",   15, 16),
    TToken(TokenType::ArrowRight,       "->",  16, 18),
    TToken(TokenType::Whitespace,       " ",   18, 19),
    TToken(TokenType::DoubleAmpersand,  "&&",  19, 21),
    TToken(TokenType::Whitespace,       " ",   21, 22),
    TToken(TokenType::DoublePipe,       "||",  22, 24),
    TToken(TokenType::Whitespace,       " ",   24, 25),
    TToken(TokenType::PathSeparator,    "::",  25, 27),
    TToken(TokenType::Whitespace,       " ",   27, 28),
    TToken(TokenType::Triangle,         "|>",  28, 30),
    TToken(TokenType::Whitespace,       " ",   30, 31),
    TToken(TokenType::ParenOpen,        "(",   31, 32),
    TToken(TokenType::ParenClose,       ")",   32, 33),
    TToken(TokenType::BracketOpen,      "[",   33, 34),
    TToken(TokenType::BracketClose,     "]",   34, 35),
    TToken(TokenType::BraceOpen,        "{",   35, 36),
    TToken(TokenType::BraceClose,       "}",   36, 37),
    TToken(TokenType::Whitespace,       " ",   37, 38),
    TToken(TokenType::LessThan,         "<",   38, 39),
    TToken(TokenType::Whitespace,       " ",   39, 40),
    TToken(TokenType::GreaterThan,      ">",   40, 41),
    TToken(TokenType::Whitespace,       " ",   41, 42),
    TToken(TokenType::Equal,            "=",   42, 43),
    TToken(TokenType::Whitespace,       " ",   43, 44),
    TToken(TokenType::Plus,             "+",   44, 45),
    TToken(TokenType::Whitespace,       " ",   45, 46),
    TToken(TokenType::Minus,            "-",   46, 47),
    TToken(TokenType::Whitespace,       " ",   47, 48),
    TToken(TokenType::Asterisk,         "*",   48, 49),
    TToken(TokenType::Whitespace,       " ",   49, 50),
    TToken(TokenType::Slash,            "/",   50, 51),
    TToken(TokenType::Whitespace,       " ",   51, 52),
    TToken(TokenType::Percent,          "%",   52, 53),
    TToken(TokenType::Whitespace,       " ",   53, 54),
    TToken(TokenType::Colon,            ":",   54, 55),
    TToken(TokenType::Whitespace,       " ",   55, 56),
    TToken(TokenType::Comma,            ",",   56, 57),
    TToken(TokenType::Whitespace,       " ",   57, 58),
    TToken(TokenType::ExclamationMark,  "!",   58, 59),
    TToken(TokenType::Whitespace,       " ",   59, 60),
    TToken(TokenType::Dot,              ".",   60, 61),
    TToken(TokenType::Whitespace,       " ",   61, 62),
    TToken(TokenType::Pipe,             "|",   62, 63)
)

pub fun symbol_merging() = assert_tokens(
    "<====>= ||> ..... ->= :::",

    TToken(TokenType::LessThanEqual,    "<=",   0,  2),
    TToken(TokenType::DoubleEqual,      "==",   2,  4),
    TToken(TokenType::Equal,            "=",    4,  5),
    TToken(TokenType::GreaterThanEqual, ">=",   5,  7),
    TToken(TokenType::Whitespace,       " ",    7,  8),
    TToken(TokenType::DoublePipe,       "||",   8, 10),
    TToken(TokenType::GreaterThan,      ">",   10, 11),
    TToken(TokenType::Whitespace,       " ",   11, 12),
    TToken(TokenType::TripleDots,       "...", 12, 15),
    TToken(TokenType::Dot,              ".",   15, 16),
    TToken(TokenType::Dot,              ".",   16, 17),
    TToken(TokenType::Whitespace,       " ",   17, 18),
    TToken(TokenType::ArrowRight,       "->",  18, 20),
    TToken(TokenType::Equal,            "=",   20, 21),
    TToken(TokenType::Whitespace,       " ",   21, 22),
    TToken(TokenType::PathSeparator,    "::",  22, 24),
    TToken(TokenType::Colon,            ":",   24, 25)
)

pub fun keywords() = assert_tokens(
    "if else ext fun return continue break val mut mod use as pub struct enum match while for",

    TToken(TokenType::KeywordIf,       "if",        0,  2),
    TToken(TokenType::Whitespace,      " ",         2,  3),
    TToken(TokenType::KeywordElse,     "else",      3,  7),
    TToken(TokenType::Whitespace,      " ",         7,  8),
    TToken(TokenType::KeywordExt,      "ext",       8, 11),
    TToken(TokenType::Whitespace,      " ",        11, 12),
    TToken(TokenType::KeywordFun,      "fun",      12, 15),
    TToken(TokenType::Whitespace,      " ",        15, 16),
    TToken(TokenType::KeywordReturn,   "return",   16, 22),
    TToken(TokenType::Whitespace,      " ",        22, 23),
    TToken(TokenType::KeywordContinue, "continue", 23, 31),
    TToken(TokenType::Whitespace,      " ",        31, 32),
    TToken(TokenType::KeywordBreak,    "break",    32, 37),
    TToken(TokenType::Whitespace,      " ",        37, 38),
    TToken(TokenType::KeywordVal,      "val",      38, 41),
    TToken(TokenType::Whitespace,      " ",        41, 42),
    TToken(TokenType::KeywordMut,      "mut",      42, 45),
    TToken(TokenType::Whitespace,      " ",        45, 46),
    TToken(TokenType::KeywordMod,      "mod",      46, 49),
    TToken(TokenType::Whitespace,      " ",        49, 50),
    TToken(TokenType::KeywordUse,      "use",      50, 53),
    TToken(TokenType::Whitespace,      " ",        53, 54),
    TToken(TokenType::KeywordAs,       "as",       54, 56),
    TToken(TokenType::Whitespace,      " ",        56, 57),
    TToken(TokenType::KeywordPub,      "pub",      57, 60),
    TToken(TokenType::Whitespace,      " ",        60, 61),
    TToken(TokenType::KeywordStruct,   "struct",   61, 67),
    TToken(TokenType::Whitespace,      " ",        67, 68),
    TToken(TokenType::KeywordEnum,     "enum",     68, 72),
    TToken(TokenType::Whitespace,      " ",        72, 73),
    TToken(TokenType::KeywordMatch,    "match",    73, 78),
    TToken(TokenType::Whitespace,      " ",        78, 79),
    TToken(TokenType::KeywordWhile,    "while",    79, 84),
    TToken(TokenType::Whitespace,      " ",        84, 85),
    TToken(TokenType::KeywordFor,      "for",      85, 88)
)

pub fun identifiers() = assert_tokens(
    "hello world111 funny foreign _test 3hi _2 ni_ce_",

    TToken(TokenType::Identifier, "hello",     0,  5),
    TToken(TokenType::Whitespace, " ",         5,  6),
    TToken(TokenType::Identifier, "world111",  6, 14),
    TToken(TokenType::Whitespace, " ",        14, 15),
    TToken(TokenType::Identifier, "funny",    15, 20),
    TToken(TokenType::Whitespace, " ",        20, 21),
    TToken(TokenType::Identifier, "foreign",  21, 28),
    TToken(TokenType::Whitespace, " ",        28, 29),
    TToken(TokenType::Identifier, "_test",    29, 34),
    TToken(TokenType::Whitespace, " ",        34, 35),
    TToken(TokenType::IntLiteral, "3",        35, 36),
    TToken(TokenType::Identifier, "hi",       36, 38),
    TToken(TokenType::Whitespace, " ",        38, 39),
    TToken(TokenType::Identifier, "_2",       39, 41),
    TToken(TokenType::Whitespace, " ",        41, 42),
    TToken(TokenType::Identifier, "ni_ce_",   42, 48)
)